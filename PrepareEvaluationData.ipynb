{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q+A with or without context and ground truth (input CSV, outputs CSV and JSONL)\n",
    "\n",
    "This notebook will help you set up an input file (`JSONL`) to use to run Azure OpenAI evaluation requiring data with `question` and `answer` pairs. (This is not designed to generate massive testing data but should work to generate spreadsheets with a few hundred (give or take) rows.)\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "#### Input file\n",
    "\n",
    "`csv` file with one column (with a header of `question`). Save the input file in the `input_files` folder. \n",
    "\n",
    "Optionally, the input file can contain a `ground_truth` column\n",
    " \n",
    "| question    | \n",
    "| -------- | \n",
    "| What color is green?  |\n",
    "| Where am I?           |\n",
    "| Do dogs like cats?    | \n",
    "\n",
    "\n",
    "\n",
    "#### Environment Variables\n",
    "\n",
    "You'll need to first create a `.env` file in the root of this directory containing values for `DC_CHAT_URL` and `DC_API_TOKEN` as shown in the `env.example` file. \n",
    "\n",
    "- To obtain the `DC_API_TOKEN` \n",
    "   - log into the Digital Collections website (either staging or production will work)\n",
    "   - then visit the corresponding staging or production API route and copy the token into the `.env` file\n",
    "     - Production: `https://api.dc.library.northwestern.edu/api/v2/auth/token`\n",
    "     - Staging: `https://dcapi.rdc-staging.library.northwestern.edu/api/v2/auth/token`\n",
    "   - Note that these tokens are by default good for 1 day so you'll need to redo these steps once it expires\n",
    "   - After updating your `.env` file you will need to **restart the kernel**\n",
    "- `DC_CHAT_URL`: Decide whether you want to hit the production or staging endpoing and use one of these values:\n",
    "  - Staging `https://pimtkveo5ev4ld3ihe4qytadxe0jvcuz.lambda-url.us-east-1.on.aws`\n",
    "  - Production `https://hdtl6p2qzfxszvbhdb7dyunuxe0dgexo.lambda-url.us-east-1.on.aws`\n",
    "\n",
    "## Output\n",
    "\n",
    "JSONL file containing records with `question` and `answer` fields (and optionally `context`)\n",
    "\n",
    "\n",
    "\n",
    "| question              | answer         |\n",
    "| --------              | -------        |\n",
    "| What color is green?  | Green.         |\n",
    "| Where am I?           | Here.          |\n",
    "| Do dogs like cats?    | No.            | \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Environment\n",
    "\n",
    "First start by importing and setting up the libraries we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install required packages\n",
    "%pip install pandas\n",
    "%pip install requests\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import json, requests\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "DC_CHAT_URL = os.getenv('DC_CHAT_URL')\n",
    "DC_API_TOKEN = os.getenv('DC_API_TOKEN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Functions to get an answer to the question\n",
    "\n",
    "def format_answer(response, with_context=False):\n",
    "    if with_context:\n",
    "        return pd.Series([response['answer'], response['context']])\n",
    "    else:\n",
    "        return response['answer']\n",
    "    \n",
    "def format_error(with_context=False):\n",
    "    if with_context:\n",
    "        return pd.Series([\"--ERROR--\", \"--ERROR--\"])\n",
    "    else:\n",
    "        return \"--ERROR--\"\n",
    "\n",
    "def get_answer(question, with_context=False):\n",
    "    url = DC_CHAT_URL\n",
    "    header = {'Content-Type': 'application/json'}\n",
    "    \n",
    "    body = {\n",
    "        'message': 'chat',\n",
    "        'auth': DC_API_TOKEN,\n",
    "        'ref': 'DEV-TEAM-TEST-' + str(random.random()),\n",
    "        \"question\": question\n",
    "    }\n",
    "    print(\"Asking question: \" + question)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json.dumps(body), headers=header)\n",
    "        response.raise_for_status()\n",
    "        print(f\"Response: {response.status_code}\")\n",
    "        if response.status_code != 200:\n",
    "            print('Status:', response.status_code, response.reason)\n",
    "            return format_error(with_context)\n",
    "        response_json = response.json()\n",
    "        return format_answer(response_json, with_context)\n",
    "    except Exception as err:\n",
    "        print(f\"Other error occurred: {err}\")\n",
    "        return format_error(with_context)\n",
    "    \n",
    "def get_answers(questions, with_context=False):\n",
    "    if with_context:\n",
    "       questions[['answer', 'context']] = questions['question'].apply(lambda x:get_answer(x, with_context))\n",
    "    else:\n",
    "        questions['answer'] = questions['question'].apply(lambda x:get_answer(x, with_context))\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure your input file and load data\n",
    "\n",
    "Setup the input file name and make sure it is readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your input file inside the `input_files` folder\n",
    "# put your input filename here\n",
    "input_filename = '40_realistic_with_ground_truth.csv'\n",
    "\n",
    "# read the input file\n",
    "questions = pd.read_csv(os.path.join('input_files', input_filename))\n",
    "\n",
    "# preview the input file\n",
    "questions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the answers from DCAPI\n",
    "\n",
    "Configure `with_context` to whether you want to fetch context along with the answers\n",
    "\n",
    "Run the below to fetch answers (and optionally context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to getenerate answers (will take some time)\n",
    "\n",
    "# Set with_context to True if you want to get the context column along with the answer\n",
    "# (Needed for some of the Azure evaluations)\n",
    "with_context = True\n",
    "\n",
    "# get answers\n",
    "result = get_answers(questions, with_context)\n",
    "\n",
    "# preview answers\n",
    "result.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the results to file\n",
    "\n",
    "It will write both `CSV` and `JSONL` files. (`JSONL` seems to be a little less buggy in Azure but YMMV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the output files\n",
    "timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "os.makedirs(os.path.join('output_files', timestamp), exist_ok=True)\n",
    "output_base_path = f\"output_files/{timestamp}\"\n",
    "jsonl_filename = os.path.join(output_base_path, f\"{os.path.splitext(os.path.basename(input_filename))[0]}.jsonl\")\n",
    "\n",
    "outJson = questions.to_json(orient=\"records\", lines=True) \n",
    "with open(jsonl_filename, 'w') as outfile:\n",
    "    outfile.write(outJson)\n",
    "\n",
    "csv_filename = os.path.join(output_base_path, f\"{os.path.splitext(os.path.basename(input_filename))[0]}.csv\")\n",
    "questions.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Output files saved to: {jsonl_filename} and {csv_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "red-team-tests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
