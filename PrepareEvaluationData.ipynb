{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Evaluation Data\n",
    "\n",
    "This notebook will help you set up an input files for running an evaluation in Azure or to run using the [ScoreAnswers Notebook](ScoreAnswers.ipynb)\n",
    "\n",
    "It will take a list of questions and get responses through DC API's chat endpoint\n",
    "\n",
    "- Input: A CSV file with a `question` and `ground_truth` column \n",
    "  - optionally a `context` column for Azure evaluations\n",
    "  - Note that for help in generating initial ground truths you can run a csv with just a question column and then rename the column\n",
    "- Output: A `CSV` and a `JSONL` file which additionally has an `answer` field\n",
    "\n",
    "\n",
    "## Prerequisite: Setup Environment Variables\n",
    "\n",
    "The notebook will need to know the lambda function url endpoint for DCAPI's syncronous chat route. \n",
    "\n",
    "- create a `.env` file in the root of this directory containing values for `DC_CHAT_URL` and `DC_API_TOKEN` as shown in the [`env.example`](env.example) file. \n",
    "- Obtain the `DC_API_TOKEN` \n",
    "   - log into the Digital Collections website (either staging or production will work)\n",
    "   - Get the token value (Note that by default the tokens last 12 hours but you can get one lasting up to a week by appending `?ttl=604800` to the query strings below\n",
    "     - Production: `https://api.dc.library.northwestern.edu/api/v2/auth/token`\n",
    "     - Staging: `https://dcapi.rdc-staging.library.northwestern.edu/api/v2/auth/token`\n",
    "   - After updating your `.env` file you will need to **restart the kernel**\n",
    "- `DC_CHAT_URL`: Decide whether you want to hit the production or staging endpoing and use one of these values:\n",
    "  - Staging `https://pimtkveo5ev4ld3ihe4qytadxe0jvcuz.lambda-url.us-east-1.on.aws`\n",
    "  - Production `https://hdtl6p2qzfxszvbhdb7dyunuxe0dgexo.lambda-url.us-east-1.on.aws`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Environment\n",
    "\n",
    "First start by importing and setting up the libraries we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install required packages\n",
    "%pip install pandas\n",
    "%pip install requests\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import json, requests\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "DC_CHAT_URL = os.getenv('DC_CHAT_URL')\n",
    "DC_API_TOKEN = os.getenv('DC_API_TOKEN')\n",
    "\n",
    "print(DC_CHAT_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Functions to get an answer to the question\n",
    "\n",
    "def format_answer(response, with_context=False):\n",
    "    if with_context:\n",
    "        return pd.Series([response['answer'], response['context']])\n",
    "    else:\n",
    "        return response['answer']\n",
    "    \n",
    "def format_error(with_context=False):\n",
    "    if with_context:\n",
    "        return pd.Series([\"--ERROR--\", \"--ERROR--\"])\n",
    "    else:\n",
    "        return \"--ERROR--\"\n",
    "\n",
    "def get_answer(question, with_context=False):\n",
    "    url = DC_CHAT_URL\n",
    "    header = {'Content-Type': 'application/json'}\n",
    "    \n",
    "    body = {\n",
    "        'message': 'chat',\n",
    "        'auth': DC_API_TOKEN,\n",
    "        'ref': 'DEV-TEAM-TEST-' + str(random.random()),\n",
    "        \"question\": question\n",
    "    }\n",
    "    print(\"Asking question: \" + question)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json.dumps(body), headers=header)\n",
    "        response.raise_for_status()\n",
    "        print(f\"Response: {response.status_code}\")\n",
    "        if response.status_code != 200:\n",
    "            print('Status:', response.status_code, response.reason)\n",
    "            return format_error(with_context)\n",
    "        response_json = response.json()\n",
    "        return format_answer(response_json, with_context)\n",
    "    except Exception as err:\n",
    "        print(f\"Other error occurred: {err}\")\n",
    "        return format_error(with_context)\n",
    "    \n",
    "def get_answers(questions, with_context=False):\n",
    "    if with_context:\n",
    "       questions[['answer', 'context']] = questions['question'].apply(lambda x:get_answer(x, with_context))\n",
    "    else:\n",
    "        questions['answer'] = questions['question'].apply(lambda x:get_answer(x, with_context))\n",
    "        \n",
    "    print(\"Done\")\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure your input file and load data\n",
    "\n",
    "Setup the input file name and make sure it is readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your input file inside the `input_files` folder\n",
    "# put your input filename here\n",
    "input_filename = '40_realistic_with_ground_truth.csv'\n",
    "\n",
    "# read the input file\n",
    "questions = pd.read_csv(os.path.join('input_files', input_filename))\n",
    "\n",
    "# preview the input file\n",
    "questions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the answers from DCAPI\n",
    "\n",
    "Configure `with_context` to whether you want to fetch context along with the answers\n",
    "\n",
    "Run the below to fetch answers (and optionally context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to getenerate answers (will take some time)\n",
    "\n",
    "# Set with_context to True if you want to get the context column along with the answer\n",
    "# (Needed for some of the Azure evaluations)\n",
    "with_context = False\n",
    "\n",
    "# get answers\n",
    "get_answers(questions, with_context)\n",
    "\n",
    "# preview answers\n",
    "questions.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the results to file\n",
    "\n",
    "It will write both `CSV` and `JSONL` files. (`JSONL` seems to be a little less buggy in Azure but YMMV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the output files\n",
    "timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "os.makedirs(os.path.join('output_files', timestamp), exist_ok=True)\n",
    "output_base_path = f\"output_files/{timestamp}\"\n",
    "jsonl_filename = os.path.join(output_base_path, f\"{os.path.splitext(os.path.basename(input_filename))[0]}.jsonl\")\n",
    "\n",
    "outJson = questions.to_json(orient=\"records\", lines=True) \n",
    "with open(jsonl_filename, 'w') as outfile:\n",
    "    outfile.write(outJson)\n",
    "\n",
    "csv_filename = os.path.join(output_base_path, f\"{os.path.splitext(os.path.basename(input_filename))[0]}.csv\")\n",
    "questions.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Output files saved to: {jsonl_filename} and {csv_filename}\")\n",
    "\n",
    "# Copy and paste the file path below to use as input for ScoreAnswers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "red-team-tests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
