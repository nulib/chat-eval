{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Evaluation Data\n",
    "\n",
    "This notebook will help you set up an input file for running an evaluation using the [ScoreAnswers Notebook](ScoreAnswers.ipynb) (or in Azure).\n",
    "\n",
    "It will take a list of questions and get responses through DC API's chat endpoint\n",
    "\n",
    "- Input: A CSV file with a `question` and `ground_truth` column \n",
    "  - optionally a `context` column (for Azure evaluations)\n",
    "  - Note that for help in generating initial ground truths you can run a csv with just questions and then rename the answer column\n",
    "- Output: A `CSV` and a `JSONL` file which additionally has an `answer` field\n",
    "\n",
    "\n",
    "## Prerequisite: Setup Environment Variables\n",
    "\n",
    "- Save these two files to the current directory:  [.env.staging](https://github.com/nulib/miscellany/blob/main/chat-eval/.env.staging) and [.env.production](https://github.com/nulib/miscellany/blob/main/chat-eval/.env.production)\n",
    "- [Login to DCAPI](https://dcapi.rdc-staging.library.northwestern.edu/api/v2/auth/login?goto=https://dcapi.rdc-staging.library.northwestern.edu/api/v2/auth/token?ttl=604800) and copy the token value\n",
    "- replace `DC_API_TOKEN` value in both files \n",
    "- Token expires in 1 week. After updating your `.env` file you will need to __**restart the kernel**__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Environment\n",
    "\n",
    "First start by importing and setting up the libraries we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install required packages\n",
    "%pip install pandas\n",
    "%pip install requests\n",
    "%pip install python-dotenv\n",
    "%pip install ipywidgets\n",
    "%pip install ipython\n",
    "\n",
    "# import required packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import json, requests\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select your environment\n",
    "\n",
    "Use the dropdown to select DCAPI's staging or production chat endpoint. (use staging unless you have a reason to use prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d9dc16e82148869be8775cb36debe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Environment:', options=(('staging', '.env.staging'), ('production', '.env.production')),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the cell, then use the dropdown to select your environment)\n",
    "env_to_use = widgets.Dropdown(\n",
    "    options=[('staging', '.env.staging'), ('production', '.env.production')],\n",
    "    description='Environment:',\n",
    ")\n",
    "\n",
    "display(env_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure you're logged in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load environment variables\n",
    "load_dotenv(env_to_use.value)\n",
    "\n",
    "DC_CHAT_URL = os.getenv('DC_CHAT_URL')\n",
    "DC_API_TOKEN = os.getenv('DC_API_TOKEN')\n",
    "DC_API_WHOAMI = os.getenv('DC_API_WHOAMI')\n",
    "\n",
    "whoami_reponse = requests.get(DC_API_WHOAMI, params=None, headers={'Authorization': 'Bearer ' + DC_API_TOKEN})\n",
    "\n",
    "# confirm environment variables loaded correctly\n",
    "if (whoami_reponse.json().get('isLoggedIn') == True):\n",
    "    print(\"You are logged in as \" + whoami_reponse.json().get('sub') + \" using \" + env_to_use.label + \" environment.\")\n",
    "else:\n",
    "    print(\"ERROR: Please check your API token.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure your input file and load data\n",
    "\n",
    "Setup the input file name and make sure it is readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell, then use the file upload widget to your input file\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='csv', \n",
    "    multiple=False  \n",
    ")\n",
    "\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the input file\n",
    "questions = pd.read_csv(io.BytesIO(uploaded_file.content))\n",
    "\n",
    "# preview the input file\n",
    "questions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load helper functions\n",
    "\n",
    "Run the cell so helper functions are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Functions to get an answer to the question\n",
    "\n",
    "def format_answer(response, with_context=False):\n",
    "    if with_context:\n",
    "        return pd.Series([response['answer'], response['context']])\n",
    "    else:\n",
    "        return response['answer']\n",
    "    \n",
    "def format_error(with_context=False):\n",
    "    if with_context:\n",
    "        return pd.Series([\"--ERROR--\", \"--ERROR--\"])\n",
    "    else:\n",
    "        return \"--ERROR--\"\n",
    "\n",
    "def get_answer(question, with_context=False):\n",
    "    url = DC_CHAT_URL\n",
    "    header = {'Content-Type': 'application/json'}\n",
    "    \n",
    "    body = {\n",
    "        'message': 'chat',\n",
    "        'auth': DC_API_TOKEN,\n",
    "        'ref': 'DEV-TEAM-TEST-' + str(random.random()),\n",
    "        \"question\": question\n",
    "    }\n",
    "    print(\"Asking question: \" + question)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json.dumps(body), headers=header)\n",
    "        response.raise_for_status()\n",
    "        print(f\"Response: {response.status_code}\")\n",
    "        if response.status_code != 200:\n",
    "            print('Status:', response.status_code, response.reason)\n",
    "            return format_error(with_context)\n",
    "        response_json = response.json()\n",
    "        return format_answer(response_json, with_context)\n",
    "    except Exception as err:\n",
    "        print(f\"Other error occurred: {err}\")\n",
    "        return format_error(with_context)\n",
    "    \n",
    "def get_answers(questions, with_context=False):\n",
    "    if with_context:\n",
    "       questions[['answer', 'context']] = questions['question'].apply(lambda x:get_answer(x, with_context))\n",
    "    else:\n",
    "        questions['answer'] = questions['question'].apply(lambda x:get_answer(x, with_context))\n",
    "        \n",
    "    print(\"Done\")\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the answers from DCAPI\n",
    "\n",
    "Configure `with_context` to whether you want to fetch context along with the answers\n",
    "\n",
    "Run the below to fetch answers (and optionally context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to getenerate answers (will take some time)\n",
    "\n",
    "# Set with_context to True if you want to get the context column along with the answer\n",
    "# (Needed for some of the Azure evaluations)\n",
    "with_context = False\n",
    "\n",
    "# get answers\n",
    "get_answers(questions, with_context)\n",
    "\n",
    "# preview answers\n",
    "questions.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the results to file\n",
    "\n",
    "It will write both `CSV` and `JSONL` files. (`JSONL` seems to be a little less buggy in Azure but YMMV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the output files\n",
    "timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "os.makedirs(os.path.join('output_files', timestamp), exist_ok=True)\n",
    "output_base_path = f\"output_files/{timestamp}\"\n",
    "jsonl_filename = os.path.join(output_base_path, f\"{os.path.splitext(os.path.basename(input_filename))[0]}.jsonl\")\n",
    "\n",
    "outJson = questions.to_json(orient=\"records\", lines=True) \n",
    "with open(jsonl_filename, 'w') as outfile:\n",
    "    outfile.write(outJson)\n",
    "\n",
    "csv_filename = os.path.join(output_base_path, f\"{os.path.splitext(os.path.basename(input_filename))[0]}.csv\")\n",
    "questions.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Output files saved to: {jsonl_filename} and {csv_filename}\")\n",
    "\n",
    "# Copy and paste the file path below to use as input for ScoreAnswers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sanity-check",
   "language": "python",
   "name": "sanity-check"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
