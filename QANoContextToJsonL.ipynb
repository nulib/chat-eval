{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q+A w/out context (JSONL)\n",
    "\n",
    "This notebook will help you set up an input file (`JSONL`) to use to run Azure OpenAI evaluation requiring data with `question` and `answer` pairs. (This is not designed to generate massive testing data but should work to generate spreadsheets with a few hundred (give or take) rows.)\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "#### Input file\n",
    "\n",
    "`csv` file with one column (with a header of `question`). Save the input file in the `input_files` folder\n",
    " \n",
    "| question    | \n",
    "| -------- | \n",
    "| What color is green?  |\n",
    "| Where am I?           |\n",
    "| Do dogs like cats?    | \n",
    "\n",
    "\n",
    "\n",
    "#### Environment Variables\n",
    "\n",
    "You'll need to first create a `.env` file in the root of this directory containing values for `DC_CHAT_URL` and `DC_API_TOKEN` as shown in the `env.example` file. \n",
    "\n",
    "- To obtain the `DC_API_TOKEN` \n",
    "   - log into the Digital Collections website (either staging or production will work)\n",
    "   - then visit the corresponding staging or production API route and copy the token into the `.env` file\n",
    "     - Production: `https://api.dc.library.northwestern.edu/api/v2/auth/token`\n",
    "     - Staging: `https://dcapi.rdc-staging.library.northwestern.edu/api/v2/auth/token`\n",
    "   - Note that these tokens are by default good for 1 day so you'll need to redo these steps once it expires\n",
    "- `DC_CHAT_URL`: Decide whether you want to hit the production or staging endpoing and use one of these values:\n",
    "  - Staging `https://pimtkveo5ev4ld3ihe4qytadxe0jvcuz.lambda-url.us-east-1.on.aws`\n",
    "  - Production `https://hdtl6p2qzfxszvbhdb7dyunuxe0dgexo.lambda-url.us-east-1.on.aws`\n",
    "\n",
    "## Output\n",
    "\n",
    "JSONL file containing records with question and answer fields\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install required packages\n",
    "%pip install pandas\n",
    "%pip install requests\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import json, requests\n",
    "from requests.exceptions import HTTPError\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "DC_CHAT_URL = os.getenv('DC_CHAT_URL')\n",
    "DC_API_TOKEN = os.getenv('DC_API_TOKEN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your input file inside the `input_files` folder\n",
    "# put your input filename here\n",
    "input_filename = '1_with_ground_truth.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the input file\n",
    "questions = pd.read_csv(os.path.join('input_files', input_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did World War II propaganda posters influe...</td>\n",
       "      <td>World War II propaganda posters played a cruci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How did World War II propaganda posters influe...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  World War II propaganda posters played a cruci...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview the input file\n",
    "questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to get an answer to the question\n",
    "\n",
    "def format_answer(response, with_context=False):\n",
    "    if with_context:\n",
    "        return pd.Series([response['answer'], response['context']])\n",
    "    else:\n",
    "        return response['answer']\n",
    "    \n",
    "def format_error(with_context=False):\n",
    "    if with_context:\n",
    "        return pd.Series([\"--ERROR--\", \"--ERROR--\"])\n",
    "    else:\n",
    "        return \"--ERROR--\"\n",
    "\n",
    "def get_answer(question, with_context=False):\n",
    "    url = DC_CHAT_URL\n",
    "    header = {'Content-Type': 'application/json'}\n",
    "    \n",
    "    body = {\n",
    "        'message': 'chat',\n",
    "        'auth': DC_API_TOKEN,\n",
    "        'ref': 'DEV-TEAM-TEST-' + str(random.random()),\n",
    "        \"question\": question\n",
    "    }\n",
    "    print(\"Asking question: \" + question)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json.dumps(body), headers=header)\n",
    "        response.raise_for_status()\n",
    "        print(f\"Response: {response.status_code}\")\n",
    "        if response.status_code != 200:\n",
    "            print('Status:', response.status_code, response.reason)\n",
    "            return format_error(with_context)\n",
    "        response_json = response.json()\n",
    "        return format_answer(response_json, with_context)\n",
    "    except Exception as err:\n",
    "        print(f\"Other error occurred: {err}\")\n",
    "        return format_error(with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to getenerate answers (will take some time)\n",
    "# questions['answer'] = questions['question'].apply(lambda x:get_answer(x)) \n",
    "with_context = True\n",
    "questions[['answer', 'context']] = questions['question'].apply(lambda x:get_answer(x, with_context))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview answers\n",
    "questions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the output files\n",
    "timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "os.makedirs(os.path.join('output_files', timestamp), exist_ok=True)\n",
    "output_base_path = f\"output_files/{timestamp}\"\n",
    "jsonl_filename = os.path.join(output_base_path, f\"{os.path.splitext(os.path.basename(input_filename))[0]}.jsonl\")\n",
    "\n",
    "outJson = questions.to_json(orient=\"records\", lines=True) \n",
    "with open(jsonl_filename, 'w') as outfile:\n",
    "    outfile.write(outJson)\n",
    "\n",
    "csv_filename = os.path.join(output_base_path, f\"{os.path.splitext(os.path.basename(input_filename))[0]}.csv\")\n",
    "questions.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Output files saved to: {jsonl_filename} and {csv_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "red-team-tests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
